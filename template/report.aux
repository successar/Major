\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Certificate}{i}{chapter*.1}}
\@writefile{toc}{\contentsline {chapter}{Certificate}{ii}{chapter*.2}}
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{iii}{chapter*.3}}
\@writefile{toc}{\contentsline {chapter}{Abstract}{iv}{chapter*.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Overview}{1}{section.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces High Level Depiction of Spoken Dialog Systems}}{2}{figure.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Objectives of this work}{4}{section.1.2}}
\citation{d1e535}
\citation{dahl}
\citation{d1e358}
\citation{d1e411}
\citation{d1e5}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{6}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Frame based SLU in a typical ATIS system}}{7}{figure.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Technical Challenges}{8}{section.2.1}}
\citation{d1e333}
\citation{d1e149}
\citation{d1e35}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Knowledge Based Solutions}{9}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Semantically Enhanced Syntactic Grammar}{9}{subsection.2.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Semantic Grammars}{9}{subsection.2.2.2}}
\citation{d1e509}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Data Driven Approaches}{10}{section.2.3}}
\citation{d1e218}
\citation{d1e252}
\citation{d1e114}
\citation{d1e218}
\citation{d1e473}
\citation{dataset-flickr30k}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Generative Models}{12}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{Semantic Priors in Understanding Models}{12}{subsection.2.3.1}}
\citation{d1e193}
\citation{raymond}
\citation{d1e56}
\citation{d1e301}
\citation{d1e193}
\citation{wang2006}
\@writefile{toc}{\contentsline {subsubsection}{Lexicalisation Models}{13}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{Implementation of Generative Models}{13}{subsection.2.3.1}}
\citation{wang2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Integrated Models}{14}{subsection.2.3.2}}
\citation{wang2006}
\citation{dataset-flickr30k}
\citation{raymond}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Conditional Models}{15}{subsection.2.3.3}}
\citation{multijoint}
\citation{cnn}
\citation{elman1990finding}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Neural Models}{16}{subsection.2.3.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Techniques used}{18}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Neural Networks}{18}{section.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Feed-forward neural nets}{19}{subsection.3.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{Linear unit}{19}{subsection.3.1.1}}
\newlabel{eq:lin}{{3.1}{19}{Linear unit}{equation.3.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Rectifier and ReLU}{19}{equation.3.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Nonlinear functions used in neural nets. }}{20}{figure.3.1}}
\newlabel{fig:nonlinear}{{3.1}{20}{Nonlinear functions used in neural nets}{figure.3.1}{}}
\newlabel{eq:rectifier}{{3.2}{20}{Rectifier and ReLU}{equation.3.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Applying dropout to a neural network. }}{21}{figure.3.2}}
\newlabel{fig:dropout}{{3.2}{21}{Applying dropout to a neural network}{figure.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Dropout}{21}{figure.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Recurrent Neural Nets}{21}{section.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces A Recurrent Neural Network (RNN). Three time-steps are shown.}}{22}{figure.3.3}}
\newlabel{fig:rnn}{{3.3}{22}{A Recurrent Neural Network (RNN). Three time-steps are shown}{figure.3.3}{}}
\newlabel{eqn:h_t}{{3.3}{22}{Recurrent Neural Nets}{equation.3.2.3}{}}
\newlabel{eqn:y}{{3.4}{22}{Recurrent Neural Nets}{equation.3.2.4}{}}
\newlabel{eqn:rnn_loss}{{3.5}{23}{Recurrent Neural Nets}{equation.3.2.5}{}}
\newlabel{eqn:rnn_loss_T}{{3.6}{23}{Recurrent Neural Nets}{equation.3.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Recurrent architectures}{23}{subsection.3.2.1}}
\newlabel{subsec:recUnits}{{3.2.1}{23}{Recurrent architectures}{subsection.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces The inputs and outputs to a neuron of a RNN}}{24}{figure.3.4}}
\newlabel{fig:rnn_node}{{3.4}{24}{The inputs and outputs to a neuron of a RNN}{figure.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Vanishing Gradient \& Gradient Explosion Problems}{24}{subsection.3.2.2}}
\newlabel{eqn:bp_rnn_error}{{3.7}{25}{Vanishing Gradient \& Gradient Explosion Problems}{equation.3.2.7}{}}
\newlabel{eqn:bp_rnn_chain}{{3.8}{25}{Vanishing Gradient \& Gradient Explosion Problems}{equation.3.2.8}{}}
\newlabel{eqn:bp_rnn_k}{{3.9}{25}{Vanishing Gradient \& Gradient Explosion Problems}{equation.3.2.9}{}}
\newlabel{eqn:bp_rnn_jaocb}{{3.10}{25}{Vanishing Gradient \& Gradient Explosion Problems}{equation.3.2.10}{}}
\newlabel{eqn:bp_rnn_k_norm}{{3.12}{26}{Vanishing Gradient \& Gradient Explosion Problems}{equation.3.2.12}{}}
\newlabel{eqn:bp_rnn_k_norm_total}{{3.13}{26}{Vanishing Gradient \& Gradient Explosion Problems}{equation.3.2.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Solution to the Exploding \& Vanishing Gradients}{26}{subsection.3.2.3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Psudo-code for norm clipping in the gradients whenever they explode}}{27}{algorithm.1}}
\newlabel{alg:clip}{{1}{27}{Solution to the Exploding \& Vanishing Gradients}{algorithm.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Gradient explosion clipping visualization}}{27}{figure.3.5}}
\newlabel{fig:clipping}{{3.5}{27}{Gradient explosion clipping visualization}{figure.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces A bi-directional RNN model}}{28}{figure.3.6}}
\newlabel{fig:birnn}{{3.6}{28}{A bi-directional RNN model}{figure.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Deep Bidirectional RNNs}{28}{subsection.3.2.4}}
\newlabel{eqn:rnn_right}{{3.14}{28}{Deep Bidirectional RNNs}{equation.3.2.14}{}}
\newlabel{eqn:rnn_left}{{3.15}{28}{Deep Bidirectional RNNs}{equation.3.2.15}{}}
\newlabel{eqn:birnn_classifier}{{3.16}{28}{Deep Bidirectional RNNs}{equation.3.2.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces A deep bi-directional RNN with three RNN layers.}}{29}{figure.3.7}}
\newlabel{fig:deepbirnn}{{3.7}{29}{A deep bi-directional RNN with three RNN layers}{figure.3.7}{}}
\newlabel{eqn:d_rnn_right}{{3.17}{29}{Deep Bidirectional RNNs}{equation.3.2.17}{}}
\newlabel{eqn:d_rnn_left}{{3.18}{29}{Deep Bidirectional RNNs}{equation.3.2.18}{}}
\newlabel{eqn:d_birnn_classifier}{{3.19}{29}{Deep Bidirectional RNNs}{equation.3.2.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Gated Recurrent Units}{30}{section.3.3}}
\newlabel{sec:grus}{{3.3}{30}{Gated Recurrent Units}{section.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces The detailed internals of a GRU}}{31}{figure.3.8}}
\newlabel{fig:GRU}{{3.8}{31}{The detailed internals of a GRU}{figure.3.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Long-Short-Term-Memories}{31}{section.3.4}}
\newlabel{sec:lstm}{{3.4}{31}{Long-Short-Term-Memories}{section.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces The detailed internals of a LSTM}}{32}{figure.3.9}}
\newlabel{fig:LSTM}{{3.9}{32}{The detailed internals of a LSTM}{figure.3.9}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Proposed Work}{34}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Background}{34}{section.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{Intent Detection}{34}{section.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces ATIS corpus sample with intent and slot annotation}}{35}{figure.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{Slot Filling}{35}{equation.4.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{RNN Language Model}{35}{equation.4.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces (a) RNN language model. (b) RNN intent detection model. The RNN output at last step is used to predict the intent class. (c) RNN slot filling model.}}{36}{figure.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}RNN for Intent Detection and Slot Filling}{36}{subsection.4.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Method 1}{37}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Model}{37}{subsection.4.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Joint online RNN model for intent detection, slot filling, and next word prediction.}}{38}{figure.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Next Step Prediction}{38}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Method 2}{39}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Model}{39}{subsection.4.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Attention Based RNN Model}}{40}{figure.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Objective Functions}{41}{subsection.4.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{Cross entropy}{41}{subsection.4.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{Ranking}{41}{equation.4.3.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Training}{42}{subsection.4.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Schedule of increasing intent contribution to the context vector along with the growing input sequence}}{43}{figure.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Inference}{43}{subsection.4.3.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results and Discussion}{45}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Data}{45}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Evaluation Metrics}{45}{section.5.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Model Training}{46}{section.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Results}{46}{section.5.4}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces ATIS test set Results}}{47}{table.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Error Analysis}{48}{section.5.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Intent Detection Errors}{48}{subsection.5.5.1}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Confusion Matrix for Intent Detection}}{49}{table.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Slot Filling Errors}{50}{subsection.5.5.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{53}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{unsrt}
\bibdata{biblio}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{54}{chapter.6}}
\bibcite{d1e535}{{1}{}{{}}{{}}}
\bibcite{dahl}{{2}{}{{}}{{}}}
\bibcite{d1e358}{{3}{}{{}}{{}}}
\bibcite{d1e411}{{4}{}{{}}{{}}}
\bibcite{d1e5}{{5}{}{{}}{{}}}
\bibcite{d1e333}{{6}{}{{}}{{}}}
\bibcite{d1e149}{{7}{}{{}}{{}}}
\bibcite{d1e35}{{8}{}{{}}{{}}}
\bibcite{d1e509}{{9}{}{{}}{{}}}
\bibcite{d1e218}{{10}{}{{}}{{}}}
\bibcite{d1e252}{{11}{}{{}}{{}}}
\bibcite{d1e114}{{12}{}{{}}{{}}}
\bibcite{d1e473}{{13}{}{{}}{{}}}
\bibcite{dataset-flickr30k}{{14}{}{{}}{{}}}
\bibcite{d1e193}{{15}{}{{}}{{}}}
\bibcite{raymond}{{16}{}{{}}{{}}}
\bibcite{d1e56}{{17}{}{{}}{{}}}
\bibcite{d1e301}{{18}{}{{}}{{}}}
\bibcite{wang2006}{{19}{}{{}}{{}}}
\bibcite{multijoint}{{20}{}{{}}{{}}}
\bibcite{cnn}{{21}{}{{}}{{}}}
\bibcite{elman1990finding}{{22}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
